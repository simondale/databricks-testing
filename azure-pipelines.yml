# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- master

stages:

- stage: build
  displayName: Build Databricks Artefacts
  pool:
    vmImage: 'ubuntu-latest'
  jobs:
  - job:
    displayName: Create Build Artefact
    steps:
      - checkout: self
      - task: CopyFiles@2
        displayName: Copy Assets to Staging Folder
        inputs:
          Contents: |
            scripts/
            notebooks/
          TargetFolder: $(Build.ArtifactStagingDirectory)
      - task: PublishBuildArtifacts@1
        displayName: Publish Artefacts
        inputs:
          PathtoPublish: $(Build.ArtifactStagingDirectory)
          ArtifactName: drop
          publishLocation: Container

- stage: Development
  dependsOn: Build
  variables:
    - group: dev
  jobs: 
  - deployment: deploy
    environment: dev
    pool:
      vmImage: 'ubuntu-latest'
    workspace:
      clean: all
    strategy:
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: drop
          - task: AzureCLI@2
            displayName: Deploy Databricks Notebooks
            inputs:
              azureSubscription: Visual Studio Enterprise(abb0e29f-b7c0-4171-a437-d4df920360ab)
              scriptType: bash
              scriptLocation: scriptPath
              scriptPath: $(Pipeline.Workspace)/drop/scripts/databricks.sh
              workingDirectory: $(Pipeline.Workspace)/drop/
            env:
              DATABRICKS_ID: $(DatabricksId)
          - task: PublishTestResults@2
            inputs:
              testResultsFormat: JUnit
              testResultsFiles: '**/TEST-*.xml'
              searchFolder: $(Pipeline.Workspace)/drop/
              mergeTestResults: true
              failTaskOnFailedTests: true
              testRunTitle: Pipeline Tests
            