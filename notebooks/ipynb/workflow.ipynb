{"cells":[{"cell_type":"markdown","source":["# Workflow\nThis notebook defines a sample data processing workflow as a set of classes. To execute the workflow, use a **driver** notebook and to test the workflow use a **tests** notebook. This promotes good coding practices around code structure and code coverage while still working within a Notebook environment."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4269c4c-f5f3-41a5-a9b2-d0e8a1ade4ab"}}},{"cell_type":"code","source":["from pyspark.sql import DataFrame, SparkSession\nfrom pyspark.sql.functions import expr, col\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48174429-d72e-4aee-a964-865c771a729e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## File Access\nThis is an abstract class that forms the interface to read/write DataFrames used by the pipeline. This allows control of the input/output file systems and files for unit testing and allows tests to execute on totally separate data in all environments."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d39d0623-fd3f-4dc7-8714-7827e8bdd883"}}},{"cell_type":"code","source":["class FileAccess:\n  def __init__(self, spark: SparkSession) -> None:\n    self.spark = spark\n  def read(self, path: str) -> DataFrame:\n    pass\n  def write(self, path: str, df: DataFrame) -> None:\n    pass"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5eba2643-73a3-440b-813c-a2be792c2d3e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## DBFS File Access\nThis class is a concrete implementation of the FileAccess class and is provided for the production pipeline. Data is read from and written to DBFS."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2806d281-8800-4440-b833-7eb3f139fac7"}}},{"cell_type":"code","source":["class DbfsFileAccess(FileAccess):\n  def read(self, path: str) -> DataFrame:\n    schema=StructType([\n      StructField('id', IntegerType(), False), \n      StructField('name', StringType(), False), \n      StructField('value', StringType(), False)\n    ])\n    return spark.read.format('csv').load(f'dbfs:/tmp/pipeline/{path}', schema=schema, header=True)\n  def write(self, path: str, df: DataFrame):\n    df.write.format('delta').mode('overwrite').save(f'dbfs:/tmp/pipeline/{path}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e192f6a-55ca-4938-be41-22c41cfd50a3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Data Workflow\nThe following class implements the data workflow"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf28f4f6-66db-4cf4-9514-2965163eecc9"}}},{"cell_type":"code","source":["class Workflow:\n  def __init__(self, spark: SparkSession, files: FileAccess) -> None:\n    self.spark = spark\n    self.files = files  \n  \n  def _process(self, df: DataFrame) -> DataFrame:\n    df = df.select(\n      col('id'), \n      expr('UPPER(name) AS name'), \n      col('value'), \n      expr('CAST(1 AS TINYINT) AS processed'), \n      expr('CURRENT_TIMESTAMP() AS processed_time')\n    )\n    return df\n  \n  def run(self) -> None:\n    df = self.files.read('raw.csv')\n    df = df.transform(self._process)\n    self.files.write('refined', df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdee517c-b165-4a1d-ad9e-d7cda26f7570"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"name":"pipeline","notebookId":3666776045961402,"application/vnd.databricks.v1+notebook":{"notebookName":"workflow","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3474342943506737}},"nbformat":4,"nbformat_minor":0}
